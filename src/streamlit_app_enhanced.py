#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í–¥ìƒëœ Streamlit ì•± - ìƒˆë¡œìš´ êµ¬ì¡°í™”ëœ íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
í‘œ ì œì™¸, overlap, LLM ë©”íƒ€ë°ì´í„° ìƒì„±ê¹Œì§€ ì™„ì „í•œ ì‹œìŠ¤í…œ
"""

import streamlit as st
import os
import subprocess
import json
import pickle

def get_venv_python(venv_name):
    venv_path = f"environments/{venv_name}/bin/python"
    if os.path.exists(venv_path):
        return venv_path
    else:
        st.error(f"ê°€ìƒí™˜ê²½ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {venv_path}")
        return None

def run_safe_subprocess(cmd, description):
    try:
        st.info(f"{description} ì‹¤í–‰ ì¤‘...")
        result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8')
        if result.returncode == 0:
            st.success(f"âœ… {description} ì™„ë£Œ!")
            if result.stdout:
                st.text("ì¶œë ¥:")
                st.code(result.stdout)
        else:
            st.error(f"âŒ {description} ì‹¤íŒ¨!")
            if result.stderr:
                st.error("ì˜¤ë¥˜:")
                st.code(result.stderr)
    except Exception as e:
        st.error(f"âŒ {description} ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def load_json_file(filename):
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        st.error(f"JSON íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def main():
    st.set_page_config(
        page_title="í–¥ìƒëœ PDF êµ¬ì¡°í™” & ì„ë² ë”© ì‹œìŠ¤í…œ",
        page_icon="ğŸš€",
        layout="wide",
        initial_sidebar_state="collapsed",
        menu_items={
            'Get Help': None,
            'Report a bug': None,
            'About': None
        }
    )
    st.title("ğŸš€ í–¥ìƒëœ PDF êµ¬ì¡°í™” & ì„ë² ë”© ì‹œìŠ¤í…œ")
    st.markdown("**í‘œ ì œì™¸, Overlap, LLM ë©”íƒ€ë°ì´í„° ìƒì„±ê¹Œì§€ ì™„ì „í•œ íŒŒì´í”„ë¼ì¸**")
    
    tab1, tab2, tab3, tab4 = st.tabs(["íŒŒì¼ ì—…ë¡œë“œ & êµ¬ì¡°í™”", "ê²°ê³¼ í™•ì¸", "ì„ë² ë”© ìƒì„±", "ì‹œìŠ¤í…œ ì •ë³´"])

    with tab1:
        st.header("ğŸ“„ íŒŒì¼ ì—…ë¡œë“œ ë° êµ¬ì¡°í™” íŒŒì´í”„ë¼ì¸")
        
        # ë°ì´í„° ê´€ë¦¬ ë²„íŠ¼
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ—‘ï¸ ê¸°ì¡´ ë°ì´í„° ì‚­ì œ", key="delete_data_btn"):
                files_to_delete = [
                    "text_only_chunks.json",
                    "final_text_only_data.json",
                    "full_pipeline_llm_enhanced_chunks.json",
                    "pymupdf_table_areas.json",
                    "data/llm_enhanced_sections.json",
                    "embeddings.faiss",
                    "embeddings_metadata.pkl",
                    "embedding_quality_report.json",
                    "embedding_quality_report_detailed.json",
                    "qa_pairs.json"
                ]
                deleted_count = 0
                for file in files_to_delete:
                    if os.path.exists(file):
                        try:
                            os.remove(file)
                            deleted_count += 1
                        except Exception as e:
                            st.error(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {file} - {e}")
                
                if deleted_count > 0:
                    st.success(f"âœ… {deleted_count}ê°œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ!")
                else:
                    st.info("ì‚­ì œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        with col2:
            if st.button("ğŸ§¹ ìºì‹œ ë° ì„ì‹œ íŒŒì¼ ì‚­ì œ", key="delete_cache_btn"):
                cache_files = [f for f in os.listdir('.') if f.endswith('.tmp') or f.endswith('.cache')]
                deleted_count = 0
                for file in cache_files:
                    try:
                        os.remove(file)
                        deleted_count += 1
                    except Exception as e:
                        st.error(f"íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {file} - {e}")
                
                if deleted_count > 0:
                    st.success(f"âœ… {deleted_count}ê°œ ìºì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ!")
                else:
                    st.info("ì‚­ì œí•  ìºì‹œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # íŒŒì¼ ì—…ë¡œë“œ
        uploaded_file = st.file_uploader("PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=['pdf'])
        if uploaded_file is not None:
            with open("input.pdf", "wb") as f:
                f.write(uploaded_file.getbuffer())
            st.success(f"âœ… {uploaded_file.name} ì—…ë¡œë“œ ì™„ë£Œ!")
            
            st.subheader("ğŸš€ í–¥ìƒëœ êµ¬ì¡°í™” íŒŒì´í”„ë¼ì¸")
            
            # íŒŒì´í”„ë¼ì¸ ì˜µì…˜
            pipeline_option = st.selectbox(
                "íŒŒì´í”„ë¼ì¸ ì„ íƒ",
                [
                    "ğŸ†• ìƒˆë¡œìš´ ì™„ì „ êµ¬ì¡°í™” íŒŒì´í”„ë¼ì¸ (ì¶”ì²œ)",
                    "ê¸°ì¡´ í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ"
                ]
            )
            
            if st.button("ğŸš€ êµ¬ì¡°í™” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰", type="primary", key="enhanced_pipeline_btn"):
                if "ìƒˆë¡œìš´ ì™„ì „ êµ¬ì¡°í™” íŒŒì´í”„ë¼ì¸" in pipeline_option:
                    # ìƒˆë¡œìš´ êµ¬ì¡°í™”ëœ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
                    st.info("ğŸ†• ìƒˆë¡œìš´ ì™„ì „ êµ¬ì¡°í™” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘...")
                    
                    # 1ë‹¨ê³„: ìƒˆë¡œìš´ êµ¬ì¡°í™”ëœ íŒŒì´í”„ë¼ì¸
                    cmd1 = ["python", "test_full_pipeline_with_llm.py"]
                    result1 = subprocess.run(cmd1, capture_output=True, text=True, encoding='utf-8')
                    
                    if result1.returncode == 0:
                        st.success("âœ… 1ë‹¨ê³„: êµ¬ì¡°í™”ëœ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
                        
                        # 2ë‹¨ê³„: Streamlit í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                        cmd2 = ["python", "src/streamlit_integration.py", "convert"]
                        result2 = subprocess.run(cmd2, capture_output=True, text=True, encoding='utf-8')
                        
                        if result2.returncode == 0:
                            st.success("âœ… 2ë‹¨ê³„: Streamlit í˜•ì‹ ë³€í™˜ ì™„ë£Œ!")
                            
                            # ê²°ê³¼ í†µê³„ í‘œì‹œ
                            if os.path.exists("final_text_only_data.json"):
                                data = load_json_file("final_text_only_data.json")
                                if data:
                                    st.success(f"ğŸ‰ ì™„ë£Œ! {len(data)}ê°œ ì²­í¬ ìƒì„±")
                                    
                                    # í†µê³„ ì •ë³´
                                    total_length = sum(item.get("content_length", 0) for item in data)
                                    avg_length = total_length / len(data) if data else 0
                                    
                                    col1, col2, col3 = st.columns(3)
                                    with col1:
                                        st.metric("ì²­í¬ ìˆ˜", len(data))
                                    with col2:
                                        st.metric("ì´ í…ìŠ¤íŠ¸ ê¸¸ì´", f"{total_length:,}ì")
                                    with col3:
                                        st.metric("í‰ê·  ì²­í¬ ê¸¸ì´", f"{avg_length:.1f}ì")
                        else:
                            st.error("âŒ Streamlit í˜•ì‹ ë³€í™˜ ì‹¤íŒ¨!")
                            if result2.stderr:
                                st.error(f"ì˜¤ë¥˜: {result2.stderr}")
                    else:
                        st.error("âŒ êµ¬ì¡°í™”ëœ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨!")
                        if result1.stderr:
                            st.error(f"ì˜¤ë¥˜: {result1.stderr}")
                else:
                    # ê¸°ì¡´ í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ
                    venv_python = get_venv_python("venv_text_new")
                    cmd = [venv_python, "src/hybrid_extraction_system.py", "input.pdf"]
                    run_safe_subprocess(cmd, "í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ")

    with tab2:
        st.header("ğŸ“Š êµ¬ì¡°í™” ê²°ê³¼ í™•ì¸")
        
        # ê²°ê³¼ íŒŒì¼ë“¤ í™•ì¸
        result_files = [
            ("final_text_only_data.json", "ìµœì¢… êµ¬ì¡°í™” ë°ì´í„° (JSON)"),
            ("full_pipeline_llm_enhanced_chunks.json", "ì›ë³¸ êµ¬ì¡°í™” ë°ì´í„° (JSON)"),
            ("embeddings.faiss", "FAISS ì„ë² ë”© ì¸ë±ìŠ¤"),
            ("embeddings_metadata.pkl", "ì„ë² ë”© ë©”íƒ€ë°ì´í„°")
        ]
        
        for filename, description in result_files:
            if os.path.exists(filename):
                st.write(f"**{description}** âœ…")
                file_size = os.path.getsize(filename)
                st.write(f"íŒŒì¼ í¬ê¸°: {file_size:,} bytes")
                
                # íŒŒì¼ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ìƒì„±
                try:
                    if filename.endswith('.json'):
                        with open(filename, 'r', encoding='utf-8') as f:
                            data = f.read()
                        mime_type = "application/json"
                    else:
                        with open(filename, 'rb') as f:
                            data = f.read()
                        mime_type = "application/octet-stream"
                    
                    st.download_button(
                        label=f"{description} ë‹¤ìš´ë¡œë“œ",
                        data=data,
                        file_name=filename,
                        mime=mime_type
                    )
                except Exception as e:
                    st.error(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            else:
                st.write(f"**{description}** âŒ (íŒŒì¼ ì—†ìŒ)")
        
        # êµ¬ì¡°í™”ëœ ë°ì´í„° ìƒì„¸ ì •ë³´
        if os.path.exists("final_text_only_data.json"):
            data = load_json_file("final_text_only_data.json")
            if data:
                st.subheader("ğŸ“ˆ êµ¬ì¡°í™” ë°ì´í„° í†µê³„")
                
                # ê¸°ë³¸ í†µê³„
                total_chunks = len(data)
                total_length = sum(item.get("content_length", 0) for item in data)
                avg_length = total_length / total_chunks if total_chunks > 0 else 0
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("ì´ ì²­í¬ ìˆ˜", total_chunks)
                with col2:
                    st.metric("ì´ í…ìŠ¤íŠ¸ ê¸¸ì´", f"{total_length:,}ì")
                with col3:
                    st.metric("í‰ê·  ì²­í¬ ê¸¸ì´", f"{avg_length:.1f}ì")
                with col4:
                    llm_processed = sum(1 for item in data if item.get("extraction_method") == "llm_ollama")
                    st.metric("LLM ì²˜ë¦¬ëœ ì²­í¬", llm_processed)
                
                # ìƒ˜í”Œ ë°ì´í„° í‘œì‹œ
                st.subheader("ğŸ“‹ ìƒ˜í”Œ êµ¬ì¡°í™” ë°ì´í„°")
                if len(data) > 0:
                    sample_data = data[:3]  # ì²˜ìŒ 3ê°œ ì²­í¬
                    for i, chunk in enumerate(sample_data):
                        with st.expander(f"ì²­í¬ {i+1}: {chunk.get('section_title', 'ì œëª© ì—†ìŒ')}"):
                            st.write(f"**ë‚´ìš©**: {chunk.get('content', '')[:200]}...")
                            st.write(f"**í˜ì´ì§€**: {chunk.get('page', 0)}")
                            st.write(f"**í‚¤ì›Œë“œ**: {', '.join(chunk.get('keywords', []))}")
                            st.write(f"**ìš”ì•½**: {chunk.get('summary', '')}")
                            st.write(f"**ì‹ ë¢°ë„**: {chunk.get('confidence', 0.5):.2f}")

    with tab3:
        st.header("ğŸ¤– ì„ë² ë”© ìƒì„±")
        
        if os.path.exists("final_text_only_data.json"):
            st.success("âœ… êµ¬ì¡°í™”ëœ ë°ì´í„°ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!")
            
            if st.button("ğŸš€ ì„ë² ë”© ìƒì„±", type="primary", key="embedding_btn"):
                venv_python = get_venv_python("venv_rag_new")
                cmd = [venv_python, "src/embedding_generator.py"]
                run_safe_subprocess(cmd, "ì„ë² ë”© ìƒì„±")
                
                # ì„ë² ë”© í’ˆì§ˆ í‰ê°€
                if os.path.exists("embeddings.faiss"):
                    st.success("âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ!")
                    
                    # QA ìŒ ìƒì„±
                    if st.button("ğŸ”„ QA ìŒ ìƒì„± ë° í’ˆì§ˆ í‰ê°€", type="primary", key="qa_btn"):
                        cmd_qa = [venv_python, "src/qa_pair_generator.py", "final_text_only_data.json", "qa_pairs.json"]
                        result_qa = subprocess.run(cmd_qa, capture_output=True, text=True, encoding='utf-8')
                        
                        if result_qa.returncode == 0:
                            st.success("âœ… QA ìŒ ìƒì„± ì™„ë£Œ!")
                            
                            # í’ˆì§ˆ í‰ê°€
                            cmd_eval = [venv_python, "src/embedding_quality_evaluator.py"]
                            result_eval = subprocess.run(cmd_eval, capture_output=True, text=True, encoding='utf-8')
                            
                            if result_eval.returncode == 0:
                                st.success("ğŸ‰ í’ˆì§ˆ í‰ê°€ ì™„ë£Œ!")
                                
                                # í‰ê°€ ê²°ê³¼ í‘œì‹œ
                                if os.path.exists("embedding_quality_report_detailed.json"):
                                    report = load_json_file("embedding_quality_report_detailed.json")
                                    if report:
                                        st.subheader("ğŸ“Š í’ˆì§ˆ í‰ê°€ ê²°ê³¼")
                                        col1, col2, col3 = st.columns(3)
                                        with col1:
                                            st.metric("ì¢…í•© ì ìˆ˜", f"{report.get('overall_score', 0):.2f}")
                                        with col2:
                                            st.metric("ë‚´ì¬ì  í‰ê°€", f"{report.get('intrinsic_score', 0):.2f}")
                                        with col3:
                                            st.metric("ì™¸ì¬ì  í‰ê°€", f"{report.get('extrinsic_score', 0):.2f}")
                            else:
                                st.error("âŒ í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨!")
                        else:
                            st.error("âŒ QA ìŒ ìƒì„± ì‹¤íŒ¨!")
        else:
            st.warning("âš ï¸ ë¨¼ì € êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")

    with tab4:
        st.header("ğŸ”§ ì‹œìŠ¤í…œ ì •ë³´")
        
        st.subheader("ê°€ìƒí™˜ê²½ ìƒíƒœ")
        venv_status = {}
        for venv_name in ["venv_web_new", "venv_text_new", "venv_rag_new"]:
            venv_path = f"environments/{venv_name}"
            if os.path.exists(venv_path):
                venv_status[venv_name] = "âœ… í™œì„±"
            else:
                venv_status[venv_name] = "âŒ ë¹„í™œì„±"
        for venv_name, status in venv_status.items():
            st.write(f"**{venv_name}**: {status}")
        
        st.subheader("íŒŒì¼ ì‹œìŠ¤í…œ ìƒíƒœ")
        important_files = [
            "input.pdf",
            "final_text_only_data.json",
            "full_pipeline_llm_enhanced_chunks.json",
            "embeddings.faiss",
            "embeddings_metadata.pkl",
            "embedding_quality_report.json",
            "qa_pairs.json"
        ]
        for file in important_files:
            if os.path.exists(file):
                size = os.path.getsize(file)
                st.write(f"**{file}**: âœ… ({size:,} bytes)")
            else:
                st.write(f"**{file}**: âŒ (ì—†ìŒ)")
        
        st.subheader("ğŸ†• ìƒˆë¡œìš´ ê¸°ëŠ¥")
        st.info("""
        **ìƒˆë¡œìš´ ì™„ì „ êµ¬ì¡°í™” íŒŒì´í”„ë¼ì¸:**
        - âœ… í‘œ ì œì™¸ ê¸°ëŠ¥
        - âœ… Overlap ì²­í‚¹ (30%)
        - âœ… LLM ë©”íƒ€ë°ì´í„° ìƒì„± (ì„¹ì…˜ ì œëª©, í‚¤ì›Œë“œ, ìš”ì•½)
        - âœ… ì˜ì–´ ì°¸ê³ ë¬¸í—Œ ìë™ í•„í„°ë§
        - âœ… JSON íŒŒì‹± ê°•í™” (100% ì„±ê³µë¥ )
        - âœ… ì™„ì „í•œ ë©”íƒ€ë°ì´í„° êµ¬ì¡°
        
        **ê¸°ì¡´ ì‹œìŠ¤í…œê³¼ ì™„ì „ í˜¸í™˜:**
        - âœ… Streamlit ì•±ê³¼ í˜¸í™˜
        - âœ… ì„ë² ë”© ìƒì„± ì‹œìŠ¤í…œê³¼ í˜¸í™˜
        - âœ… í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œê³¼ í˜¸í™˜
        """)

if __name__ == "__main__":
    main() 